\documentclass[a4paper,12pt,titlepage]{article}

\usepackage[numbib,notlot,nottoc]{tocbibind}
\input{preamble}
\usepackage{algpseudocode}
\usepackage{hyperref}
\usepackage[figure]{hypcap}
\usepackage{dashrule}
\usepackage{forloop}

\bibliographystyle{ugost2008}

\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\geometry{left=3cm}
\geometry{right=3cm}
\geometry{top=3cm}
\geometry{bottom=2cm}

\linespread{1.1}

\newcommand*{\fig}[1]{рис. ~{\ref{fig:#1}}}
\newcommand*{\chp}[1]{<<\nameref{chap:#1}>>}
\newlength{\unit}
\setlength{\unit}{1cm}

\title{Анализ критичности инструкций, и исследование его применения в компиляторе}
\author{Заостровных Арсений Юрьевич. 813 группа ФРТК МФТИ.}

\begin{document}

\input{title}
\tableofcontents
\pagebreak
\section{Введение}
\epigraph{ — В то время, когда наши космические корабли бороздят просторы Вселенной…}{Леонид Гайдай}
Во времена экспоненциального роста потребления вычислительных мощностей исправно выполняемый на протяжении ни одного десятилетия прогноз Давида Хауса по удвоению производительности каждые полтора года даёт сбои. Этому есть несколько причин.
 Во-первых размер обыкновенного полевого транзистора всегда больше длины нескольких атомов. Поэтому число транзисторов в микросхеме ограниченного размера не может быть выше физического предела, и этот предел не далёк. Intel прямо сейчас строит фабрику в Аризоне по выпуску чипов 14нм технологического процесса, шаг кристаллической решётки кремния составляет около 5\AA: получается всего 28 атомов в одном элементе. Близость границы не позволяет поддерживать традиционный экспоненциальный рост. В этом аспекте возможно будет прорыв при переходе на другой физический процесс - оптическое или квантовое взаимодействие.
 Во-вторых всё возрастающая частота сигнала синхронизации накладывает ограничение на расстояние, которое может пройти импульс за один такт. Это автоматически означает, что бессмысленно увеличивать частоту одноядерного процессора выше некоторого лимита, который опять же уже рядом. Современные частоты процессоров уже превысили отметку в 8ГГц, что при максимальной скорости распространения сигнала в $3*10^{10}{\dfrac{\text{см}}{c}}$ оставляет участок достижимости радиусом меньше чем в 4см.
 Отсюда необходимо следует дробление одной микросхемы процессора на несколько ядер и параллелизацию вычислений. Так возникает <<в-третьих>> -- далеко не все задачи эффективно распараллеливаются, а бесплатно -- и подавно единицы.

Эта ситуация заставляет производителей в погоне за лидерство в классе высокопроизводительных машин выдумывать архитектуры откровенно эксплуатирующие параллелизм. Такие как, например, суперскаляр или VLIW. У каждой из них, разумеется, есть свои недостатки. Очередной попыткой создать архитектуру имеющую только достоинства предшественниц является проект, в котором проходила преддипломная практика. Проект состоит из относительно простого оборудования, позволяющего параллельное исполнения с минимальным количеством наведённых зависимостей и бинарного транслятора, который и осуществляет основную работу по созданию и оптимизации потоков исполнения. Архитектура позволяет сокращать время исполнения участков кода, используя дополнительные ресурсы.

Однако не все участки одинаково важны. Давно известно, что ускорение исполнения цепочки операций далеко не всегда приводит к росту производительности. А если это ускорение достигнуто за счет использование дополнительных ресурсов ЭВМ, то результат может быть о вовсе негативным. Становится ясно, что для каждой инструкции необходимо угадывать будет ли она узким местом всё программы. Для отражения этого факта используется термин критический путь в графе потока данных. Всю программу можно представить как поток данных, перемещающихся от производителей к потребителям. Исполнение начинает с одной вершины графа зависимостей и заканчивает другой. Кратчайший путь в таком графе называется критическим. Как много не имелось бы ресурсов у машины она не сможет исполнить всю программу быстрее исполнения одной непрерывной цепочки последовательно зависимых операций, проходящей вдоль критического пути. Такая терминология позволяет говорить, что если операция не лежит на критическом пути, то ускорение её исполнения не приведёт к повышению эффективности всей программы, а возможно даже помешает другим, более важным, инструкциям.

Таким образом, задача сводится к отысканию критического пути. Однако в силу специфики проекта, вычислители не обладают достаточной памятью для журналирования всего исполнения. Поэтому в распоряжении транслятора есть только исходный код и некоторая относительно скудная профильная информация. Поэтому условия задачи переформулируются до оценки вероятности попадания каждой конкретной инструкции на критический путь. Операции, имеющие некоторую существенную вероятность, называются критичными.

\subsection{Цель работы}
Сравнение предсказаний статического анализа критичности с точными результатами, полученными динамически, доработка его. После чего внедрение учета этой классификации в фазу распределения физических регистров и исследования влияния полученных правок на результирующую производительность.

\pagebreak
\subsection{Основные термины и понятия}
Здесь содержится список жаргонных слов и понятий, так близких разработчикам компиляторов, что от них очень трудно избавиться.
\begin{description}
	\item[Перевязка] - операция, сдерживающая выполнение текущего потока, в ожидании завершения старых операций. Необходима для обеспечение зависимостей по данным (WaW, RaW, WaR).
	\item[Длина перевязки] - число тактов, в терминах последовательного исполнения, до самой дальней из инструкций, от которых зависит рассматриваемая.
	\item[Убить поток] - освободить занятое им устройство, или ячейку в очереди.
	\item[Гейт] (gate - ворота, англ.) - операция, стопорящая спекулятивно запущенный поток исполнения до разрешения определённого предиката. Как только предикат вычисляется, машина либо убивает замороженный поток, либо продолжает его.
	\item[Гамак] - условное разветвление с последующим схождением в графе потока управления (он выглядит как нижние 4 вершины на \fig{cfg-spec} на ~\pageref{fig:cfg-spec} странице).
	\item[Стор] (store - положить, англ.) - операция сохраняющая значение, лежащие в регистре по указанному адресу в памяти.
	\item[Лоад] (load - загрузить, англ.) - операция загрузки значения из ячейки памяти с данным адресом в определённый регистр.
	\item[Веб] (web - паутина, англ.) - подграф DF графа описывающий зависимости по одной конкретной переменной.
	\item[Динамическая зависимость] - зависимость между операциями, выявленная во время исполнения кода.
	\item[Бранч] (branch - ветка, англ.) - Разветвление в графе передачи потока управления, вызванное условным переходом.
	\item[Рекуррентность] (recurrentis - возвращающийся, лат.), так же рекуррентная цепь - последовательность операций цикла, каждая из которых зависит от предшествующей, и первая зависит от последней. (см. \fig{recurrency} на ~\pageref{fig:recurrency} странице)
	\item[CPA] - Critical Path Analisys - инструмент направленный на построение критического пути графа динамических зависимостей по журналам исполнения программы на симуляторе.
\end{description}

\subsection{Краткий обзор литературы}
В одном из первых докладов, утилизирующих идея неравновесности инструкций, \cite{dualpath} исследована возможность спекулятивного исполнения сразу двух веток для обоих вариантов разрешения предиката на ограниченной аппаратуре. Там подчеркивается важность тщательного выбора бранча, и используются критерии подобные описанным в разделе \chp{statsign}, но по накопленному динамическому профилю аналогично статистике по направлению разрешения.
Тогда потребовался ряд дополнительных аппаратных решений для внедрения технологии, в проекте, в котором проходила практика, вся почва уже подготовлена, и динамический профиль доступен оптимизирующему двоичному транслятору, поэтому чтобы не усложнять вычислительное устройство лучше реализовать это программно. Что и делается как частный случай анализа критичности. В работе \cite{loads} исследовано влияние задержки конкретных лоадов на общую производительность. А в \cite{localvscritical} уже предложен метод предсказания критичности операций загрузки из памяти. Объединённая команда Intel и университета Меллона и Карнеги в \cite{nonvital} исследовала насколько эффективно эксплуатируется кеш и нашла, что большая часть строк в нем расположены совершенно бесполезно. Одновременно они предложили понятие <<жизненный лоад>> и испытали кеш, работающий только с таковыми, получив прирост производительности около 17\%.
В \cite{isca} идея неравнозначности операций обобщена с бранчей и лоадов уже на все инструкции и проведено исследование её применения не только для предотвращения ненужных спекуляций, но и для неравномерного распределения аппаратных ресурсов, таких как арифметико-логические устройства, регистры, порты, <<предикторы>>. В этой работе также информация о критичности накапливается динамически в процессе исполнения в дополнительных запоминающих блоках. В этой работе, как и в первой, публикуется заманчивый прирост производительности: 10\% в среднем от уточнённого планирования инструкций по вычислительным устройствам и 5\% -- от избирательной спекуляции по данным.
Публикация \cite{dynpred} дополняет описанную в \cite{isca} технику ещё пятью динамическими признаками критичности инструкций и измеряет из эффективность. В работе \cite{pact} понятие важности операции расширяется от бинарного (критична/не критична) до многозначного (степень критичности) и проводятся некоторые обобщения работы источников. Пьер Салверда с соавторами, в \cite{construct} начали переносить анализ критичности на программный уровень, используя полный код и профильную информацию о вероятностях значений предикатов, они моделировали поведение, строя множество возможных трасс исполнения. Они показали, что критический путь может быть построен программно не менее точно, чем аппаратно. Между тем, программная имплементация гораздо менее требовательна к аппаратуре.

\subsection{Описание архитектуры}
Архитектура, на базе которой была проведена квалификационная дипломная работа, основана на явной эксплуатации инструкционного параллелизма, найденного компилятором в программе. Эта работа была частью разработки бинарного транслятора. В изначально последовательно написанной программе как правило большинство фрагментов спроектированы в предположении, что все предыдущие части уже исполнены скалярным устройством. Поскольку корректный бинарный транслятор должен быть абсолютно незаметен, он может позволить исполнять 2 участка параллельно, только если докажет, что они совершенно не зависят друг от друга.

Поэтому, ожидая разрешения всех зависимостей очередного участка, очень редко удаётся задействовать существующие ресурсы параллельной вычислительной машины. Чтобы занять простаивающие средства, многие операции можно исполнить <<спекулятивно>> то есть предположив, что зависимости разрешились некоторым образом. Различают виды спекулятивности (спекулятивного исполнения) по типам зависимостей.

\subsection{Спекулятивность по управлению}
Одна из типичных ситуаций в алгоритмах - <<гамак>>. Последовательно такой участок, как представлен на \fig{cfg-spec} слева, обрабатывался бы так, как показано по центру. Чтобы его ускорить, задействовав простаивающие мощности, можно не дожидаясь, когда придёт из памяти значение предиката $p$ начать выполнение всех возможных путей развития.
\begin{figure}[h]
	\begin{minipage}[h]{0.32\linewidth}
		\centering
		\input{control-spec-graph}
		\caption{Выполнение участка программы: последовательно и параллельно на трёх устройствах.}
	\end{minipage}
	%\hfill
	\begin{minipage}[h]{0.57\linewidth}
		\centering
		\input{control-spec-ways} 
	\end{minipage}
	\label{fig:cfg-spec}
\end{figure}
 И только в месте, где они могут повлиять на видимое состояние машины поставить <<гейт>> (см. Основные термины), который уничтожит следы эксплуатирования неверного значения предиката. Пусть типичная операция чтения исполняется около 200 тактов. Это значительно больше, чем время исполнения <<гейта>>. Тогда несложно подсчитать, что исполнение куска программы от чтения предиката, до момента начала записи по адресу $x_4$ ускорилось почти в два раза.
Но ничто не даётся бесплатно, и нетрудно видеть, что общее количество вычислений (а вместо простого чтения это могли быть обширные вычисления) увеличилось в полтора раза, что может сказаться на количество потреблённой энергии, а также может помешать параллельному исполнению другого кода (поскольку заняты два дополнительных устройства).
\subsection{Спекулятивность по данным}
Другой распространённый тип - зависимость по данным. Если в исходной последовательной программе следом друг за другом идут операции записи и чтения по вычисляемому адресу, который не удаётся предсказать статически, то всегда есть вероятность пересечения их целевых адресов, и автоматически выстраивается дуга зависимости по данным.

\begin{figure}[h!]
	\centering
	\input{data-spec-ways}
	\caption{Выполнение участка кода: неспекулятивно и спекулятивно, на двух устройствах.}
	\label{fig:data-spec-ways}
\end{figure}
 Однако, как правило, адреса всё же оказываются разными. Чтобы использовать это обстоятельство поступают следующим образом (см. \fig{data-spec-ways}):
 на параллельный конвейер подаётся зависимая цепочка, а после вычисления адреса сравниваются, и в случае совпадения, наработки второго вычислителя отменяются, и выполняется повторная загрузка, на этот раз, правильного значения.
 Такой подход опять позволяет сократить время почти в полтора раза, но не всегда. Если адреса неожиданно совпали, то помимо небольшой задержки на сравнение адресов, расходуются вычислительные мощности. Таким образом  в худшем случае количество вычислений удвоится, но при избытке аппаратуры это не заметно (не считая энергопотребления). Обыкновенно адреса разнятся, и относительно последовательного исполнения лишней была лишь операция сравнения. Это весьма неплохая цена за двукратное ускорение. Поскольку, как уже сказано, адреса очень редко совпадают, эта техника достаточно эффективна.
Распределение регистров, напротив, не выявляет никаких скрытых свойств у инструкций, но требует финальный вид графа зависимостей для оптимальной работы. Поэтому эта фаза одна из последних перед кодогенерацией.
%\subsection{}

\subsection{Стадии трансляции}
\begin{wrapfigure}{r}{0.3\textwidth}
	\vspace{-1.5cm}
	\input{compile-chain}
	\vspace{-0.5cm}
	\caption{Положение анализа критичности среди фаз компиляции.}
	\label{fig:compilation-phases}
	\vspace{-2cm}
\end{wrapfigure}

Процесс бинарной трансляции для удобства разработки разбит на последовательные фазы. Каждая фаза, или стадия компиляции, или трансляции опирается на результаты предыдущей - использует структуры данных и учитывает результаты анализа. Поэтому стадии имеют ограниченную свободу перестановок.
Информация о критичности может пригодиться на любой стадии оптимизации. Поэтому анализ критичности проводится одной из первых фаз этапа оптимизации - сразу после построения основной структуры внутреннего представления. Это порождает одну из основных проблем. Последующие стадии меняют код с которым работают, поэтому результаты анализа вскоре устаревают, и в некоторых случаях могут оказаться неактуальны или попросту неверны к моменту использования. Противомера -- проведение анализа после каждого изменения программы может оказаться слишком расточительно в боевых условиях, когда оптимизирующая ретрансляция отнимает время у исполняемой полезной нагрузки. В дальнейшем с развитием описываемой технологии необходимо разработать методику оценки актуальности результатов.

\pagebreak
\section{Анализ критичности}
Анализ критичности - это попытка оценить вероятность прохождения критического пути программы через конкретную операцию. Анализ производится статически на ранней фазе компиляции, на основе профиля и умозрительных заключений. Его результаты должны быть использованы в последующих фазах оптимизации и распределения ресурсов. Основные проблемы такого подхода - принципиально вероятностная оценка, локальность (анализируется одна или несколько близких операций) и несоответствие анализируемого кода выходному (программа может быть изменена в любой последующей фазе).
\subsection{Статические признаки критичности}
\label{chap:statsign}
\subsubsection{Сторы без профильной информации}
Как уже было сказано, анализ строго консервативен - выявляет только заведомо не задерживающие операции. Поэтому если стор, который, как известно, очень часто тормозит исполнение никак не проявил себя при сборе профиля лучше на всякий случай счесть его критическим. Чтобы в случае срабатывания какого-нибудь редкого бранча, вариант трансляции, основанный на результатах анализа, повёл себя не хуже исходного.
\subsubsection{Сторы близкие к выходу из региона}
В отсутствие межпроцедурного анализа нельзя сказать, какие операции зависят от таких сторов. Эта ситуация подобна отсутствию профиля, поэтому как и в первом случае они консервативно считаются критичными. Выход из региона - это конец региона, либо <<call>> - специальная операция вызова процедура, которая, как правило, расположена в другом регионе трансляции.
\subsubsection{Сторы конфликтующие с лоадом}
Такие сторы лежат на критическом пути только в двух случаях:
\begin{itemize}
	\item Конфликтный лоад критичен\\
		Тут опять же из консервативности, для недопущения помехи хоть в каком-нибудь, даже маловероятном, случае этот стор, как и любая другая зависимость лоада считается критичным.
	\item Конфликтный лоад близок по графу передачи потока управления\\
		Лоады как правило запускаются в спекулятивном предположении, что конфликта не было, поэтому, когда таковой обнаруживается происходит откат к чекпоинту - очень дорогая операция, через которую наверняка пройдёт критический путь. Поэтому и здесь нельзя дискриминировать стор. Эта политика главным образом применялась когда в профиле не было информации о конфликтах, близость операций по графу потока управления, в силу принципа локальность с большой вероятностью влечёт за собой их конфликт, поэтому такая эвристика имела смысл. В данный момент, благодаря более подробной обратной связи, она избыточна.
\end{itemize}
В остальных случаях сторы воздействуют лишь на память, от которой не зависит ближайшее будущее исполнения, значит эти операции записи можно безболезненно откладывать.

\subsubsection{Трудно предсказуемый предикат}
При встрече бранча, предикат которого в подавляющем большинстве случаев (большинство определяется константой) разрешается однозначно компилятор может использовать две стратегии поведения: 
\begin{enumerate}
	\item Заставить исполнителя ждать разрешения предиката
	\item Запустить обе ветки спекулятивно, убив одну из них когда значение станет известно
\end{enumerate}
\begin{figure}[h]
	\centering
	\input{cancelation}
	\caption{Пример работы алгоритма отмены критичности.}
	\label{fig:cancelation}
\end{figure}
Оба варианта неприятны, поскольку первый увеличивает время исполнения данной нити, а второй - потребляемые ресурсы. 
Если хотя бы в одной из веток гамака содержится критическая операция, то выгоднее запустить исполнение спекулятивно, в этом случае время жизни ложной ветви, а значит и количество использованных вхолостую ресурсов устройства, определяется скоростью вычисления предиката. В этом случае разрешение предиката - критическая операция.
 Так же приходится проверять, является ли именно данный предикат причиной разветвления в рассматриваемом линейном участке - технический момент реализации. Для уточнения признака, имплементирован механизм отмены критичности для предикатов, в гамаках которых после проверки всех признаков не окажется неотложных инструкций.
%\pagebreak
\begin{algorithmic}
	\Function {cancel} { $operation$ }
		\If {$operation$ is \underline{critical dependency} $\land\not\exists$ critical child}
			\ForAll {$dep \in DF.preds ( operation ) $}
			\State {mark $dep$ as a \bf{non} critical}
			\State \Call {cancel} {$dep$}
			\EndFor
		\EndIf
	\EndFunction
\end{algorithmic}
%\todo{Этот algorithmic надо расположить целиком на одной странице}

Здесь различаются подлинно критичные инструкции и зависимости таковых ( подробнее смотри в разделе \chp{Propogation}). На \fig{cancelation} -- пример работы алгоритма, начало - предикат. Здесь красные стрелки показывают направление рекурсивных вызовов, зачеркнутые означают невыполнение условия отмены, штриховка - удаление признака критичности.

\subsubsection{Лоад, часто промахивающийся в кеш}
Здесь всё просто. Если адрес для загрузки из памяти содержится в быстром кеше, операция очень мало задерживает исполнение. Однако когда необходимое значение не было предварительно подгружено, происходит запрос в далёкую оперативную память, ответ на который приходит отнюдь не спешно, что сильно тормозит процесс. Поэтому часто грешащие таким поведением инструкции имеет смысл выполнять приоритетно.
\subsubsection{Лоад без профильной информации}
Как и в первом случае, в отсутствие статистики консервативный анализ критичности не может дискриминировать операцию потому, что лоад может оказаться таким, какой описан выше.
\subsubsection{Операции, работающие с физическими объектами}
Существует большой класс задач по не критичной к времени обработке данных. Однако чаще встречаются задачи, заключающиеся в быстром вычислении реакции на некоторые внешние воздействия. Взаимодействие ЭВМ с внешним миром осуществляется с помощью особых объектов, называемых физическими. Обычно время выполнения программы измеряется от сигнала раздражения, пришедшего на некий объект до сигнала реакции, появившегося на другом (или на том же) объекте. В такой модели использования критический путь всегда начинается и заканчивается операциями работы с физическими объектами. Значит они всегда лежат на этом пути - то есть являются критическими.

\subsubsection{Рекуррентные цепи}
Рекуррентная последовательность - это кольцо зависимых друг от друга операций цикла. Главная проблема такого образование в том, что они создают зависимость каждой итерации цикла от предыдущей. Поэтому не удаётся исполнить каждую итерацию в отдельном параллельном потоке. 
Таким образом время исполнения всего цикла, при достаточном количестве параллельных вычислителей, определяется лишь длиной максимальной рекуррентной цепи. 
\begin{figure}[!!h]
\begin{minipage}[]{0.35\linewidth}
	По этой причине важно придать этим операциям максимальный приоритет при оптимизации. Это и делает анализ, находя такие цепочки и помечая их как критичные.
	Например исполнение такого цикла:
	\begin{algorithmic}
	\Repeat 
	\State {$list.val \gets list.val^2 $}
	\State {$list \gets list.next$}
	\Until {$list \neq \textbf{null}$}
	\end{algorithmic}

	Более подробно выглядящего так:
	\[
	\begin{matrix*}[l]
	loop:& \ld b a\\
			&\mul b {b*b}\\
			&\st a b\\
			&\inc a\\
			&\ld a a\\
			&\brnz a {loop}
	\end{matrix*}
	\]
	Будет выглядеть как показано на рисунке (после переименования регистров вместо $a$ используются $r_0, r_2$, а вместо $b$ -- $r_1, r_3$ )
	\vspace{0.5cm}
	\caption{Пример рекуррентной цепочки операций}
\end{minipage}
\hspace{0.05\linewidth}
\begin{minipage}[]{0.4\linewidth}
	\centering
	\input{recurrency}
\end{minipage}
\label{fig:recurrency}
\end{figure}

\subsection{Пропагация критичности}
\label{chap:Propogation}
Просто найти операции по перечисленным выше признакам недостаточно. Если время схода операции с конвейера определяет длительность исполнения программы, то важно запустить её на исполнение как можно раньше. Для этого необходимо разрешить все её зависимости. Следовательно одна из зависимостей этой инструкции тоже является критической. Иначе говоря, если операция не является началом программы, но лежит на критическом пути, значит дуга её зависимости тоже содержится там. Значит и инструкция - начинающая дугу - лежит на пути.\\
Поскольку не известно какая именно из них критична, а анализ консервативен ( задача определить операции, которые попадут на критический путь с наименьшей вероятностью) помечаются все предки по графу зависимостей. Формально это выражается:
\begin{algorithmic}
\Function {propagate} { $operation$ }
	\ForAll {$dep \in data\_flow.predcessors ( operation ) $}
		\State {mark $dep$ as a \bf{critical dependency }}
		\State \Call {propogate} {$dep$}
	\EndFor
\EndFunction
\end{algorithmic}
Здесь инструкция отмечается именно как <<зависимость критичной>>. Это необходимо, чтобы при такой же рекурсивной отмене критичности некой операции в дальнейшем, различать, какая операция считается тормозящей сама по себе, а какая - нет.
\begin{figure}[h]
\centering
\input{crit-propogation}
\caption{Пример работы пропагации критичности.}
\label{fig:crit-propogation}
\end{figure}
\subsection{Сравнение с реальным критическим путём}
\label{chap:CPAcomparison}
Для оценки справедливости приведённых выше признаков, был разработан скрипт сравнения результатов анализа критичности с данными CPA - инструмента поиска критического пути по журналам исполнения. CPA-tool принимает во внимание все динамические зависимости, строит по ним граф исполнения и ищет в нём критический путь. Поскольку тесты бывают весьма объёмные приходится работать в поточном режиме, поэтому найденный критический путь не всегда соответствует действительности, но, как показала практика, погрешность в длине в большинстве случаев не более 10\%.
Для сравнения реализован дамп списков критических и некритических операций для каждого региона, а также достигнута договорённость с командой разрабатывающей CPA-tool об его выходном формате. После разбора результатов CPA и импорта списков критических и некритических операций скрипт строит четыре множества:
\begin{itemize}
 \item $Crit_{CPA}$ - операции лежащие на критическом пути согласно CPA
 \item $Crit$ - операции отмеченные маркером критичности в процессе анализа
 \item $Noncrit$ - операции \textbf{не} отмеченные как критичные в процессе анализа
 \item $LPS$ - операции обрабатываемые особым образом, в силу того, что они принадлежат явно распараллеливаемому цикловому участку кода. По этой причини, они опускаются из рассмотрения
\end{itemize}
Эти наборы затем фильтруются, для исключения вспомогательных, не несущих смысловой нагрузки операции. Работа проводится только с регионами, исполнение которых продлилось существенное время, они перечислены в отдельном файле, содержащем статистику симулятора.
\begin{figure}[h]
\centering
\input{critical-sets}
\caption{Диаграмма Эйлера множеств критичности операций}
\label{fig:critical-sets}
\end{figure}
Из этих множеств далее формируются стандартные оценочные комбинации\cite{inforetreive}:
\begin{description}
	\item[$TN$] $\defeq (Crit\setminus LPS)\cap Crit_{CPA}$ - операции, которые были помечены критичными и действительно попали на критический путь
	\item[$FP$] $\defeq (Noncrit\setminus LPS)\cap Crit_{CPA}$ - инструкции считавшиеся некритичными, но попавшие на критичный путь по версии CPA - минимизируемое в первую очередь множество
	\item[$TP$] $\defeq (Noncrit\setminus LPS)\setminus Crit_{CPA}$ - не критичные инструкции верно распознанные на этапе анализа - множество за счет которого будут выделяться ресурсы <<горячим>> операциям
	\item[$FN$] $\defeq (Crit\setminus LPS)\setminus Crit_{CPA}$ - инструкции помеченные критичными в фазе анализа, но не оказавшиеся таковыми в динамике.
	\item[$New$] $\defeq Crit_{CPA}\setminus (Crit \cup Noncrit)$ - Операции созданные на более поздних этапах (см. \fig{compilation-phases}) и попавшие на критический путь. Их объективно нельзя было учесть, поэтому они тоже не рассматриваются.
\end{description}
Уже по ним можно оценивать статические предсказания: точность $P\defeq\frac{\parallel TP \parallel}{\parallel TP \cup FP \parallel}$ -- доля верно угаданных статическим анализом операций из всех помеченных им как некритические. И полноту $R\defeq\frac{\parallel TP \parallel}{\parallel TP \cup FN \parallel}$ -- доля верно размеченных инструкций из всех не попавших на критический путь. Здесь норма вычисляется двумя способами: это либо количество инструкций, либо суммарная доля критического пути проведённая в этом множестве. Поскольку профильная информация о времени критического пути занятого каждой операцией имеется только по командам, по которым этот путь вообще прошёл, по последней норме можно вычислить только ошибку $Err_{clk}\defeq \frac{\parallel FP \parallel_{clk}}{\parallel FP \cup TN \parallel_{clk}}$. Для оценки релевантности вычисляется также ещё величина $Rel\defeq\frac{\parallel TP \cup FN\parallel}{\parallel Crit_{CPA} \parallel}$ - доля критического пути, попавшая в поле зрения статического анализа - то есть уже существовавшая к моменту запуска фазы и относящаяся к скалярному коду.
\begin{figure}[h]
\centering
\include{error-massive}
\vspace{-1cm}
\caption{Значения ошибки и соответствующая доля критического пути.}
\label{fig:error-massive}
\end{figure}

На \fig{error-massive} отображены не все тесты, а остаток после фильтра по релевантности большей 10\% исключительно для наглядности. Таким образом можно видеть, что на многих трассах, анализу подвергается слишком малое число значимых инструкций. Поэтому имеет смысл отфильтровать более жестко, по $Rel > 50$. Тогда Значительная часть трассы окажется в поле зрения статического анализа и появится состав, по которому можно будет строить суждения о эффективности и правдоподобии. Что получилось изображено на \fig{error-50}.
\begin{figure}[!hb]
\include{error-50}
\vspace{-1cm}
\caption{Значения ошибки и соответствующая доля критического пути для трасс, подверженных значительному анализу.}
\label{fig:error-50}
\end{figure}

\pagebreak
Этот и последующие графики в этой секции будут приводятся для этих тестов. Полнота и точность вычислены с использованием первой нормы, то есть количества инструкций в множестве. Замечание: На \fig{precision} изменён масштаб по вертикальный оси.

\begin{figure}[!hb]
\include{precision}
\caption{Точность $P=\frac{\parallel TP \parallel}{\parallel TP \cup FP \parallel}$ для релевантного набора трасс.}
\label{fig:precision}
\end{figure}
Как можно видеть из \fig{recall} полнота предсказаний анализа хромает. Иными словами, далеко не все операции, которые считались критичными во время компиляции оказались таковыми на практике. В среднем лишь 35\% из них потом действительно попало на критический путь. И это нельзя назвать недостатком, поскольку консерватизм -- первейшее правило такого рода анализа. Если он из стремления к увеличению полноты предсказаний не сочтёт критичную операцию таковой в неопределённой ситуации, то она будет несправедливо дискриминирована в дальнейшем, что негативно скажется на времени исполнении всей программы. Поэтому в двузначных ситуациях эдакие <<тёмные лошадки>> на всякий случай считаются критичными, от чего полнота и оказывается не на высоте.
\begin{figure}[!h]
\include{recall}
\caption{Полнота $R=\frac{\parallel TP \parallel}{\parallel TP \cup FN \parallel}$ для релевантного набора трасс.}
\label{fig:recall}
\end{figure}

\newpage
\subsection{Применение}
Результаты анализа критичности могут иметь множество приложений, как то: разделение операций по потокам исполнения, распределение регистров или расстановка гейтов. Поскольку, как описано выше, все спекуляции повышают требуемую пропускную способность вычислительной шины для конкретного участка, приходится применять их только к некоторым частям программы. Значит необходимо выделить критические участки, что и поможет сделать описываемый анализ.
При прохождении фазы распределения регистров, информация о критичности позволяет увеличить расстояния уникальности ячеек для сдерживающих операций за счёт свободных. Благодаря этому возможно удлинение перевязок и тем самым ослабление искусственно введённых зависимостей - следствия аппаратных ограничений, что повлечёт увеличение степени параллелизма и скорости исполнения.

\subsubsection{Реализация}
Распределитель регистров преследует цель введения минимального числа зависимостей индуцированных ограниченностью памяти процессора. Для этого проводится анализ <<жизненности>> -- востребованности переменных и размечаются области программы (<<вебы>>), где нельзя покушаться на значение того или иного виртуального регистра. Это значит, что, этот виртуальный регистр был распределён в один и тот же физический вместе с некоторым другим, логически никак с ним не связанным, то во время исполнения такой области на каком-либо из устройств - будет запрещено пользоваться вторым. Это и есть самая настоящая наведённая зависимость. Чтобы уменьшить число таких дополнительных дуг в DF графе, распределитель вычисляет расстояния между всеми <<вебами>>  - как минимальная из всех дистанций во всех парах вершин, первая из которых принадлежит одному вебу, а вторая -- другому. Находит ближайшие из них и старается сопоставить их с разными физическими регистрами. Если аппаратных регистров достаточно много, а программа не велика, то может случиться взаимно однозначное соответствие между виртуальными и реальными регистрами. Однако чаще физических регистров нехватает. В таком случае, в первую очередь распределяются в одну и ту же аппаратную ячейку виртуальные регистры, соответствующие самым удалённым <<вебам>>.

Для исследования эффекта, на этапе оценки расстояний между <<вебами>> различных регистров, они искусственно (<<виртуально>>) увеличиваются для тех, которые используют операции, признанные некритичными. В общем виде, это выглядит так:
\begin{algorithmic}
\If {noncritical ( operation at the end of the dependency )}
	\State {distance $\gets$ \Call {enlarge} {distance}}
\EndIf
\end{algorithmic}
Где \textsc{enlarge} - функция двух видов:
\begin{itemize}
	\item \textsc{enlarge} $( x ) \defeq multiplier*x$
	\item \textsc{enlarge} $( x ) \defeq \max(x, trashold)$
\end{itemize}
Иначе говоря, это расстояние либо умножается на фиксированное число - параметр, множитель, либо увеличивается пока не будет больше или равно заданного значения - порога. При этом стоит отметить, что для хранения расстояния была, вероятно в целях преждевременной экономии, как обычно, выбрана переменная очень малоразрядного типа, в силу чего, пока не была поставлена проверка, частенько происходило переполнение.
\begin{figure}[!h]
\include{impress}
\caption{Зависимость относительного времени исполнения от коэффициента раздвигания вебов(<<агрессивности>>) для трёх характерных трасс}
\label{fig:impress}
\end{figure}

\pagebreak

В обоих вариантах были исследованы зависимости числа тактов исполнения от соответствующего параметра - multiplier(множитель) и trashold(пороговое значение). 
Модифицированные версии были запущены на всех доступных тестовых трассах для нескольких фиксированных значений параметров. Результаты этих прогонов расположены в соответствующем на \fig{positive-perf} и \fig{negative-perf}.
Для минимизации полного времени исполнения заданной трассы, проводилось исследование влияния параметра <<агрессивности>> -- величины дискриминации некритичных операций на итоговою производительность, который для данной стратегии учета результатов анализа в распределителе регистров означает соответственно множитель или порог. Однако общей закономерности уловить не удалось.
 На \fig{impress} читатель может наблюдать, что каждая трасса по своему реагирует на подобное <<раздвигание>> вебов, и хотя, безусловно, существуют значения, в которых производительность возрастает но их расположение не очевидно.

\begin{figure}[h]
\include{correlation}
\caption{Тринадцать различных трасс. Попытка найти корреляцию независимых параметров.}
\label{fig:correlation}
\end{figure}

 Для выведения эмпирического правила автоматического определения оптимального коэффициента, была исследована корреляция точки минимума и <<рейта>> - среднего расстояния между вебами. Для этого очень детально промерялись чертова дюжина трасс разного характера - дающих преимущественный выигрыш, проигрыш в производительности парочка нечувствительных к производимым манипуляциям. Для каждой трассы было получено две сотни точек, две сотни запусков цикла ретрансляции и симуляции. Из них выбиралась точка соответствующая минимальному достигнутому времени работы, и ставилась в соответствие с <<рейтом>> соответствующим чистому запуску. При рассмотрении полученного множества следует учесть, что неформально <<рейт>> ограничен значением примерно 220 инструкций, которое считается наибольшим, поэтому горизонтальная ось простирается только до него. Значения мультипликатора изначально лежали от 0.7 до 10, и как можно наблюдать, диапазон не зря начинается до единицы. Результат на \fig{correlation}, из него видно, что корреляции не прослеживается.

\subsubsection{Идеализация}
Наиболее точным способом оценки эффективности применения статического критического анализа является сравнение его результатов с идеальным случаем, в котором нет ошибок, P=R=1. Идеализация также показывает <<потолок>> технологии - максимальный результат, которого можно добиться только чисто теоретически при данной модели применения предсказаний анализа. Для того, чтобы добиться этого был использован всё тот же CPA -- инструмент анализа критического пути по динамическим журналам симулятора (смотри раздел \chp{CPAcomparison}). Таким образом к профильной информации для каждой операции добавляется ещё и присутствие или не присутствие её на критическом пути. Запуск производится дважды - один раз чистый, с дампами симулятора и прогоном CPA по журналам, и, затем, этот файл добавляется к данным для перекомпиляции, где фаза критического анализа подставляет его в качестве своего результата. Производительность запуска перекомпилированной трассы сравнивается с исходной и это отношение наносится на график вместе с <<честным>> вариантом. Если получится стабильный прирост эффективности, такой метод стоит исследовать сам по себе, поскольку данные о критичности динамический бинарный транслятор рано или поздно будет иметь, а, следовательно, и использовать для оптимизаций. На \fig{ideal} изображены зависимости в тех же осях, что и на прежнем графике, для одной и той же трассы, для нормального и идеального анализов. Из рисунка видно, что принципиальные перспективы у подобных предсказателей есть.
\begin{figure}[h]
\include{idcmp}
\caption{Идеальный вариант анализа.}
\label{fig:ideal}
\end{figure}
\subsubsection{Рандомизация}

В качестве противоположной крайности выступает абсолютно бездумный предсказатель, основывающийся лишь на генераторе случайных чисел. Здесь название <<рандомизация>> выбрано как словоформа жаргонного термина <<рандом>>, что с английского random - случайный.
\begin{figure}[!h]
\include{rndcmp}
\caption{Случайностный вариант анализа.}
\label{fig:random}
\end{figure}
Такой вариант был реализован чрезвычайно просто: критичность операции определялась на основе чётности её номера. Если уникальный номер инструкции делится на 2, тогда она считается критичной, иначе он полагается некритичной. Конечно распределение идентификаторов инструкций отнюдь не случайно, а напротив, строго предопределено, но это только плюс выбранной стратегии, обеспечивающий воспроизводимость результатов. Также к плюсам можно отнести скорость - никаких дополнительных вычислений, кроме маскирования -- одной из простейших операций делать не приходится. И непредсказуемость, так как порядковый номер зависит практически от всех фаз компиляции и малейшая деталь в процессе, например, вставка новой операции одним махом инвертирует всю картину. В свете полученного ответа, достаточно просто достигать точности, меньшей, чем у аналитического варианта.
Этот подход позволял добиться примерно такого же отношения мощностей множеств, на которые делятся операции, что и после реального анализа. В остальном всё по той же схеме, что и при идеализации. Это делалось для оценки влияния точности анализа на итоговую производительность. Сравнение можно наблюдать на \fig{random}. С первого взгляда, не заметив легенду, невозможно угадать который из них абсолютно случаен. Это говорит о том, что даже столь малая погрешность недостаточно для уверенного дискриминирования операций, считающихся некритичными. Нужна большая точность.

\begin{figure}[!h]
\include{positive-perf}
\caption{Влияние изменений распределителя регистров на производительность. <<агрессивность>> = 0.81 }
\label{fig:positive-perf}
\end{figure}

\subsubsection{Результаты}


На \fig{positive-perf} и \fig{negative-perf} изображены изменения производительности связанные с внедрением вышеописанного раздвигания вебов регистров некритичных операций согласно показаниям анализа критичности. На \fig{positive-perf} использован коэффициент <<агрессивности>> 0.81 и не смотря на большой общий разброс среднее арифметическое оказалось больше нуля.
\begin{figure}[h]
\include{negative-perf}
\caption{Влияние изменений распределителя регистров на производительность. <<агрессивность>> = 1.30}
\label{fig:negative-perf}
\end{figure}

На \fig{negative-perf} отражено влияние немного изменённого коэффициента - 1.30 и среднее арифметическое уже упало ниже нуля.
Это лишь пара характерных примеров, в действительности среднее скачет совершенно не предсказуемо, и, хотя это проделано не было, наверное будет вести себя как и отдельная трасса, изображённая на \fig{impress}. Этот факт ещё раз говорит о чрезвычайной случайности результата, и не готовности текущей системы пользоваться результатами анализа. Единственное положительное суждение, которое можно сделать из этих двух гистограмм, состоит в том, что такое вот виртуальное раздвигание вебов действительно влияет на производительность действительно влияет на производительность. Также можно заключить, что не все трассы чувствительны к этому. Видно, что время исполнения преобладающего числа трасс осталось на том же уровне, что и было без правок. Это те трассы, где <<давление>> на регистры, то есть отношение количества необходимых к общему числу мало. В таком случае расстояния между вебами весьма велики, и изменения некоторых их них даже в несколько раз не усугубляет положение распределителя, у которого есть достаточно аппаратных регистров для каждой переменной. Можно было исключить их их рассмотрения, однако это изменило бы лишь размах колебаний среднего значения в три-четыре раза не более того. Всё ещё остаётся загадкой, как же можно выбрать оптимальную <<агрессивность>>.

\subsubsection{Анализ}
\begin{figure}[h]
\include{h264-10}
\caption{Мутации горячего цикла в процессе компиляции}
\label{fig:h264-10}
\end{figure}
В целях обнаружения причины замедления некоторых трасс при субъективно точном анализе, были исследованы некоторые из них. Вот один из примеров таких замедлений. В трассе h264-10, которая по существу представляет собой один горячий цикл, было явное обилие коротких зависимостей(красная дуга на левом \fig{h264-10}). Для облегчения компилятору была передана опция предлагающая раскрутить цикл вдвое. Этот трюк неудался, и чтобы настоять пришлось отключить также ряд проверок в исходном коде. Однако после раскрутки время исполнения кода, как ни странно, не упало. В результате детального анализа трассы исполнения, обнаружена короткая перевязка, такая как изображены на правой стороне \fig{h264-10}. Как удалось выяснить с помощью отладчика, это результат прохода одной из фаз глобальных оптимизаций -- peephole. Там есть немало правил, упрощающий код. В данном случае, было справедливо замечено, что $y=x-1$ и $x=y-1$ в соответствующих местах использования. И, не смотря на то, что системой команд предусмотрены операции записи в память по адресу со смещением, сами выполняющие подобные арифметические операции сложения или вычитания, <<оптимизатор>> подставил эти готовые значения, не заботясь о близости переопределения переменных и длине наведённой антизависимости. Для запрета применения этого правила к конкретным инструкциям, пришлось довольно глубоко внедриться в её недры. Хотя общего правила, характеризующего подобные ситуации позволяющего во всех без исключения случаях гарантировать только неуменьшение производительности и неувеличение зависимостей, особенно коротких, ещё не выработано, в данном конкретном примере отмена его позволила значительно ускорить трассу.

Итого: сразу несколько эвристик запретили сделать раскрутку цикла даже после ручной наводки через опцию компилляции, и правила, призванные повышать эффективность кода на деле только повышают связность графа потока данных. Следует вывод: общие глобальные оптимизации, такие как, например, раскрутка цикла и свертка некоторых подвыражений ещё не достаточно хороши, чтобы можно было исследовать применение анализа критичности и его влияние на время исполнения.

\section{Благодарности}
Огромная благодарность всей команде проекта, за непрерывную информационную поддержку, отзывчивость и желание помочь. Спасибо менеджеру команды Дмитрию Михайловичу Масленникову за чуткое руководство и задание курса. Научному руководителю Евгению Подкорытову за неустанные объяснения и ответы на мои непрерывные вопросы. Спасибо Арнольду Леонидовичу Плоткину за заботу о нашей учебной группе. Льву Румянцеву за предоставленный диплом \cite{lev}, который служил образцом оформления этой работы. Спасибо одногруппникам, особенно Денису Анисимову за помощь в решении многочисленных технических вопросов. Соседям по комнате и родным за моральную поддержку.

\newpage
\section{Заключение}
В работе была проведена подробная и многосторонняя оценка предсказаний статического анализа критичности использующего накопленную профильную информацию относительно точно построенного критического пути. По результатам сравнения выявлены и устранены неточности признаков критичности неопределённого предиката, и конфликтного лоада. Учёт классификации операций внедрён в фазу распределения физических регистров и исследовано изменение производительности вызванное изменениями.

 По результатам анализа замедления некоторых трасс предложены общие оптимизации, которые не были сделаны в автоматическом режиме. Продемонстрирована не состоятельность применения его в распределителе регистров при текущем состоянии компилятора, но показана принципиальная перспективность подобного рода анализа.

\newpage
\bibliography{literature}

\listoffigures

%\newpage
%\section*{Для заметок}
%\newcounter{ct}
%\forloop{ct}{1}{\value{ct} < 41}
%{
%\textcolor{black!20}{\rule{\linewidth}{1pt}}
%\\
%}
\end{document}
